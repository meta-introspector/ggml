active_personality_id: 0
auto_update: false
binding_name: llama_cpp_official
ctx_size: 2048
debug: false
discussion_prompt_separator: '!@>'
enable_gpu: true
host: localhost
model_name: null
n_predict: 1024
n_threads: 8
override_personality_model_parameters: false
personalities:
- english/generic/lollms
port: 9600
repeat_last_n: 40
repeat_penalty: 1.2
seed: -1
temperature: 0.9
top_k: 50
top_p: 0.95
use_user_name_in_discussions: false
user_avatar: default_user
user_description: ''
user_name: ''
version: 11
